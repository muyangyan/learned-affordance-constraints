{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import shelve\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from prolog.prolog_generation import PrologData\n",
    "\n",
    "from data.ag.action_genome import AG\n",
    "\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split: train length: 6388\n",
      "split: val length: 798\n",
      "split: test length: 799\n",
      "[ 185  573   72   93  287  401  118   24  443  321   53    5  767   62\n",
      "  219   76 2059  158  864  607  371  131  770  335   43  445  419   33\n",
      "  135  274  166  475  113]\n",
      "[ 20  78   3   8  48  49  14   5  54  45   8   3  82  10  28  12 253  32\n",
      " 103  76  37  12 107  32   4  53  45   4  12  29   9  45  10]\n",
      "[ 20  79  15  10  49  40  16   5  60  37  13   0  96  11  21  15 256  21\n",
      " 124  93  43  12 106  45   7  57  39   5  16  34  22  69  15]\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "root = '/data/Datasets/ag/'\n",
    "subset_file = 'data/ag/subset_shelve'\n",
    "train_ag = AG(root, no_img=True, split='train', subset_file=subset_file)\n",
    "val_ag = AG(root, no_img=True, split='val', subset_file=subset_file)\n",
    "test_ag = AG(root, no_img=True, split='test', subset_file=subset_file)\n",
    "print(train_ag.verb_label_counts)\n",
    "print(val_ag.verb_label_counts)\n",
    "print(test_ag.verb_label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ag\n",
      "ag\n",
      "ag\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "# Load prolog data\n",
    "train_pd = PrologData('prolog', 'ag', train_ag, train_ag.object_classes, train_ag.relationship_classes, train_ag.verb_classes, model=None, split='train')\n",
    "\n",
    "val_pd = PrologData('prolog', 'ag', val_ag, val_ag.object_classes, val_ag.relationship_classes, val_ag.verb_classes, model=None, split='val')\n",
    "\n",
    "test_pd = PrologData('prolog', 'ag', test_ag, test_ag.object_classes, test_ag.relationship_classes, test_ag.verb_classes, model=None, split='test')\n",
    "\n",
    "train_pd.write_bk()\n",
    "train_pd.init_general_bias()\n",
    "\n",
    "val_pd.write_bk()\n",
    "test_pd.write_bk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "awaken 0.015037593984962405\n",
      "close 0.058646616541353384\n",
      "cook 0.002255639097744361\n",
      "dress 0.006015037593984963\n",
      "drink 0.03609022556390978\n",
      "eat 0.03684210526315789\n",
      "fix 0.010526315789473684\n",
      "grasp 0.0037593984962406013\n",
      "hold 0.0406015037593985\n",
      "laugh 0.03383458646616541\n",
      "lie 0.006015037593984963\n",
      "make 0.002255639097744361\n",
      "open 0.061654135338345864\n",
      "photograph 0.007518796992481203\n",
      "play 0.021052631578947368\n",
      "pour 0.009022556390977444\n",
      "put 0.19022556390977444\n",
      "run 0.02406015037593985\n",
      "sit 0.0774436090225564\n",
      "smile 0.05714285714285714\n",
      "sneeze 0.027819548872180452\n",
      "snuggle 0.009022556390977444\n",
      "stand 0.08045112781954887\n",
      "take 0.02406015037593985\n",
      "talk 0.0030075187969924814\n",
      "throw 0.03984962406015038\n",
      "tidy 0.03383458646616541\n",
      "turn 0.0030075187969924814\n",
      "undress 0.009022556390977444\n",
      "walk 0.02180451127819549\n",
      "wash 0.006766917293233083\n",
      "watch 0.03383458646616541\n",
      "work 0.007518796992481203\n"
     ]
    }
   ],
   "source": [
    "def exp_curve(b,x):\n",
    "    return 1-np.exp(-b*x)\n",
    "\n",
    "dataset = val_ag\n",
    "for verb_idx, verb_name in enumerate(dataset.verb_classes):\n",
    "\n",
    "    freq = dataset.verb_label_counts[verb_idx]\n",
    "    ratio = freq/len(dataset)\n",
    "    print(verb_name, ratio)\n",
    "\n",
    "    #keeps negatives according to the frequency of the verb\n",
    "    train_pd.write_verb(verb_name, keep_prob=exp_curve(4, ratio)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ilp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
