{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "#from torch_geometric.data import Data\n",
    "#from torch_geometric.loader import DataLoader\n",
    "\n",
    "from data.ag.action_genome import AG\n",
    "\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "\n",
    "from models.rgcn import RGCN\n",
    "from torchvision.models import vit_b_16, ViT_B_16_Weights, VisionTransformer\n",
    "\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split: train length: 6388\n",
      "split: test length: 1597\n"
     ]
    }
   ],
   "source": [
    "root = '/data/Datasets/ag/'\n",
    "train_set = AG(root, split='train', subset_file='data/ag/subset_shelve')\n",
    "test_set = AG(root, split='test', subset_file='data/ag/subset_shelve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=16, collate_fn=train_set.verb_pred_collate)\n",
    "test_loader = DataLoader(test_set, batch_size=1, collate_fn=test_set.verb_pred_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "\n",
    "class ViT(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ViT, self).__init__()\n",
    "        vit = vit_b_16(weights=ViT_B_16_Weights.DEFAULT)\n",
    "        vit.heads = torch.nn.Identity()\n",
    "\n",
    "        #freeze the backbone\n",
    "        for param in vit.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        #set the head to use our num classes\n",
    "        vit.heads = torch.nn.Linear(vit.hidden_dim, num_classes)\n",
    "        self.vit = vit\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.vit(x)\n",
    "\n",
    "class JointModel(nn.Module):\n",
    "    def __init__(self, rgcn_params, vit_hidden_dim, num_classes):\n",
    "        super(JointModel, self).__init__()\n",
    "        num_obj_classes, node_feature_size, rgcn_hidden_dim, num_rel_classes = rgcn_params\n",
    "        self.rgcn = RGCN(num_obj_classes, node_feature_size, rgcn_hidden_dim, num_rel_classes)\n",
    "        self.vit = ViT(vit_hidden_dim)\n",
    "        self.head = nn.Linear(vit_hidden_dim + rgcn_hidden_dim, num_classes)\n",
    "    \n",
    "    def forward(self, img, sg):\n",
    "        img = self.vit(img)\n",
    "        sg = self.rgcn(sg)\n",
    "        hidden_state = torch.cat((img, sg), dim=1)\n",
    "        return self.head(hidden_state)\n",
    "\n",
    "def train(model, loader, weight, device, epochs=1, lr=1e-2):\n",
    "    criterion = torch.nn.CrossEntropyLoss(weight=weight)\n",
    "\n",
    "    model = model.to(device)\n",
    "    P = model.parameters()\n",
    "\n",
    "    optimizer = torch.optim.Adam(P, lr=lr)\n",
    "\n",
    "    for e in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for batch in tqdm(loader):\n",
    "            ids, imgs, sgs, verbs, labels = batch\n",
    "\n",
    "            labels = labels.to(device)\n",
    "            sgs = sgs.to(device)\n",
    "            imgs = imgs.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            if isinstance(model, RGCN):\n",
    "                out = model(sgs)\n",
    "            elif isinstance(model, ViT):\n",
    "                out = model(imgs)\n",
    "            elif isinstance(model, JointModel):\n",
    "                out = model(imgs, sgs)\n",
    "            else:\n",
    "                raise ValueError(f'Unknown model type: {model.__class__}')\n",
    "\n",
    "            loss = criterion(out, labels)\n",
    "\n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(out, 1)\n",
    "            _, labels_1d = torch.max(labels, 1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels_1d).sum().item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        print(f'Epoch {e} loss: {epoch_loss} accuracy: {correct/total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 33 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 718/718 [02:31<00:00,  4.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 3475.786923289299 accuracy: 0.04938164082912384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 718/718 [02:34<00:00,  4.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss: 4240.812429666519 accuracy: 0.06775823027347153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 718/718 [02:40<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 loss: 4299.314756035805 accuracy: 0.08195436335133252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 718/718 [02:32<00:00,  4.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 loss: 2834.35235619545 accuracy: 0.10102769552342797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 718/718 [02:45<00:00,  4.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 loss: 2970.202409505844 accuracy: 0.11383034314579342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 718/718 [02:31<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 loss: 2792.954768061638 accuracy: 0.10921442257446438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 718/718 [02:42<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 loss: 3402.575664460659 accuracy: 0.10912732973349591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 718/718 [02:37<00:00,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 loss: 3129.4967131614685 accuracy: 0.10755965859606341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 718/718 [02:50<00:00,  4.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 loss: 3237.4125183820724 accuracy: 0.11487545723741509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 718/718 [02:33<00:00,  4.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 loss: 3269.2235572338104 accuracy: 0.1145270858735412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "epochs = 10\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "node_feature_size = 32\n",
    "num_obj_classes = len(train_set.object_classes)\n",
    "num_verb_classes = len(train_set.verb_classes)\n",
    "num_rel_classes = len(train_set.relationship_classes)\n",
    "print(num_obj_classes, num_verb_classes, num_rel_classes)\n",
    "\n",
    "rgcn = RGCN(num_obj_classes, node_feature_size, num_verb_classes, num_rel_classes)\n",
    "vit = ViT(num_verb_classes)\n",
    "\n",
    "rgcn_hidden_dim, vit_hidden_dim = 32, 32\n",
    "rgcn_params = (num_obj_classes, node_feature_size, rgcn_hidden_dim, num_rel_classes)\n",
    "joint_model = JointModel(rgcn_params, vit_hidden_dim, num_verb_classes)\n",
    "\n",
    "weight = len(train_set) / (num_verb_classes * train_set.verb_label_counts)\n",
    "weight = torch.tensor(weight, dtype=torch.float).to(device)\n",
    "\n",
    "train(joint_model, train_loader, weight, device, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identity()\n",
      "768\n",
      "torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.models import vit_b_16, ViT_B_16_Weights\n",
    "\n",
    "# Load pre-trained ViT model\n",
    "model = vit_b_16(weights=ViT_B_16_Weights.DEFAULT)\n",
    "\n",
    "model.heads = torch.nn.Identity()\n",
    "print(model.heads)\n",
    "print(model.hidden_dim)\n",
    "\n",
    "# Prepare input\n",
    "img = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "# Forward pass\n",
    "output = model(img)\n",
    "print(output.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trying pytorch lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ilp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
