{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import tensorboard\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from data.ag.action_genome import AG\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from models.rgcn import RGCN\n",
    "from models.vit import ViT\n",
    "from models.joint_model import JointModel\n",
    "\n",
    "import pytorch_lightning as L \n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import torchmetrics\n",
    "\n",
    "from pyswip import Prolog\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#warnings.filterwarnings(\"default\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split: train length: 6388\n",
      "split: val length: 798\n",
      "split: test length: 799\n"
     ]
    }
   ],
   "source": [
    "root = '/data/Datasets/ag/'\n",
    "train_set = AG(root, split='train', split_file='data/ag/split_train_val_test.json', subset_file='data/ag/subset_shelve')\n",
    "val_set = AG(root, split='val', split_file='data/ag/split_train_val_test.json', subset_file='data/ag/subset_shelve')\n",
    "test_set = AG(root, split='test', split_file='data/ag/split_train_val_test.json', subset_file='data/ag/subset_shelve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=16, collate_fn=train_set.verb_pred_collate, num_workers=16, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=128, collate_fn=val_set.verb_pred_collate, num_workers=16, shuffle=False)\n",
    "test_loader = DataLoader(test_set, batch_size=128, collate_fn=test_set.verb_pred_collate, num_workers=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trying pytorch lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying pytorch lightning\n",
    "\n",
    "class JointModelLightning(L.LightningModule):\n",
    "    def __init__(self, model_params, weight, model_type='joint'):\n",
    "        super().__init__()\n",
    "        self.model_type = model_type\n",
    "        rgcn_params, vit_hidden_dim, num_classes = model_params \n",
    "        if model_type == 'joint':\n",
    "            self.model = JointModel(rgcn_params, vit_hidden_dim, num_classes)\n",
    "        elif model_type == 'rgcn':\n",
    "            num_obj_classes, node_feature_size, rgcn_hidden_dim, num_rel_classes = rgcn_params\n",
    "            self.model = RGCN(num_obj_classes, node_feature_size, num_classes, num_rel_classes, head=True)\n",
    "        elif model_type == 'vit':\n",
    "            self.model = ViT(num_classes, head=True)\n",
    "        self.weight = weight\n",
    "        self.constraints = None\n",
    "        \n",
    "        #epoch metrics\n",
    "        self.train_accuracy = torchmetrics.Accuracy(task='multiclass', num_classes=num_classes)\n",
    "        self.val_accuracy = torchmetrics.Accuracy(task='multiclass', num_classes=num_classes)\n",
    "        self.test_accuracy = torchmetrics.Accuracy(task='multiclass', num_classes=num_classes)\n",
    "        \n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "    def forward(self, img, sg):\n",
    "        if self.model_type == 'rgcn':\n",
    "            return self.model(sg)\n",
    "        elif self.model_type == 'vit':\n",
    "            return self.model(img)\n",
    "        else:\n",
    "            return self.model(img, sg)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        ids, imgs, sgs, verbs, labels = batch\n",
    "        out = self(imgs, sgs)\n",
    "        \n",
    "        loss = F.cross_entropy(out, labels, weight=self.weight)\n",
    "        out, labels = torch.argmax(out, dim=1), torch.argmax(labels, dim=1)\n",
    "        acc = self.train_accuracy(out, labels)\n",
    "        \n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        self.log('train_acc', acc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        ids, imgs, sgs, verbs, labels = batch\n",
    "        out = self(imgs, sgs)\n",
    "        out, labels = torch.argmax(out, dim=1), torch.argmax(labels, dim=1)\n",
    "        val_acc = self.val_accuracy(out, labels) \n",
    "        \n",
    "        #self.log('val_loss', val_loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        self.log('val_acc', val_acc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "            \n",
    "        #return val_loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        ids, imgs, sgs, verbs, labels = batch\n",
    "        out = self(imgs, sgs)\n",
    "        \n",
    "        test_loss = F.cross_entropy(out, labels, weight=self.weight)\n",
    "        out, labels = torch.argmax(out, dim=1), torch.argmax(labels, dim=1)\n",
    "        test_acc = self.test_accuracy(out, labels) \n",
    "        \n",
    "        self.log('test_loss', test_loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        self.log('test_acc', test_acc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "            \n",
    "        return test_loss\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 33 26\n",
      "[ 183  585   74   93  314  394  114   28  655  335   64    8  765   64\n",
      "  227   85 2052  161  869  636  356  122  799  442   44  442  392   27\n",
      "  129  272  172  488  103]\n",
      "tensor([ 1.9033,  0.5954,  4.7068,  3.7452,  1.1092,  0.8840,  3.0553, 12.4394,\n",
      "         0.5318,  1.0397,  5.4422, 43.5379,  0.4553,  5.4422,  1.5344,  4.0977,\n",
      "         0.1697,  2.1634,  0.4008,  0.5476,  0.9784,  2.8549,  0.4359,  0.7880,\n",
      "         7.9160,  0.7880,  0.8885, 12.9001,  2.7000,  1.2805,  2.0250,  0.7137,\n",
      "         3.3816], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "node_feature_size = 32\n",
    "num_obj_classes = len(train_set.object_classes)\n",
    "num_verb_classes = len(train_set.verb_classes)\n",
    "num_rel_classes = len(train_set.relationship_classes)\n",
    "print(num_obj_classes, num_verb_classes, num_rel_classes)\n",
    "\n",
    "rgcn_hidden_dim, vit_hidden_dim = 32, 32\n",
    "rgcn_params = (num_obj_classes, node_feature_size, rgcn_hidden_dim, num_rel_classes)\n",
    "model_params = (rgcn_params, vit_hidden_dim, num_verb_classes)\n",
    "\n",
    "print(train_set.verb_label_counts)\n",
    "weight = len(train_set) / (num_verb_classes * train_set.verb_label_counts)\n",
    "weight = torch.tensor(weight, dtype=torch.float).to(device)\n",
    "print(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA RTX 6000 Ada Generation') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4]\n",
      "\n",
      "  | Name           | Type               | Params | Mode \n",
      "--------------------------------------------------------------\n",
      "0 | model          | ViT                | 85.8 M | train\n",
      "1 | train_accuracy | MulticlassAccuracy | 0      | train\n",
      "2 | val_accuracy   | MulticlassAccuracy | 0      | train\n",
      "3 | test_accuracy  | MulticlassAccuracy | 0      | train\n",
      "--------------------------------------------------------------\n",
      "25.4 K    Trainable params\n",
      "85.8 M    Non-trainable params\n",
      "85.8 M    Total params\n",
      "343.296   Total estimated model params size (MB)\n",
      "155       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7:  29%|██▉       | 207/719 [00:16<00:41, 12.23it/s, v_num=0, train_loss_step=5.090, val_acc=0.0459, train_loss_epoch=3.440, train_acc=0.0646]"
     ]
    }
   ],
   "source": [
    "model_type = 'vit'\n",
    "\n",
    "# Initialize model and trainer\n",
    "lightning_model = JointModelLightning(model_params, weight, model_type=model_type)\n",
    "\n",
    "# Setup callbacks and logger\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='checkpoints/',\n",
    "    filename='joint-model-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=3,\n",
    "    mode='max',\n",
    ")\n",
    "\n",
    "logger = TensorBoardLogger(\"lightning_logs\", name=f\"{model_type}_model\")\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=10,\n",
    "    accelerator='gpu',\n",
    "    devices=[0],\n",
    "    callbacks=[checkpoint_callback],\n",
    "    logger=logger,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(lightning_model, train_dataloaders=train_loader, val_dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /home/muyang/learned-affordance-constraints/checkpoints/joint-model-epoch=06-val_acc=0.16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4]\n",
      "Loaded model weights from the checkpoint at /home/muyang/learned-affordance-constraints/checkpoints/joint-model-epoch=06-val_acc=0.16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 11/11 [00:00<00:00, 18.99it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.1647482067346573\n",
      "     test_loss_epoch         3.276085376739502\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss_epoch': 3.276085376739502, 'test_acc': 0.1647482067346573}]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the model\n",
    "trainer.test(dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the model with constraints\n",
    "trainer.test(dataloaders=test_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_rules(rules_file, bk_file, test_size, targets, labels=None):\n",
    "    print('Testing learned rules=====================')\n",
    "    preds = []\n",
    "\n",
    "    _ = Prolog()\n",
    "\n",
    "    Prolog.consult(rules_file)\n",
    "    Prolog.consult(bk_file)\n",
    "\n",
    "    for i in range(test_size):\n",
    "        pred = np.zeros(len(targets))\n",
    "        for j,v in enumerate(targets):\n",
    "            q = Prolog.query(f'{v}_target(x{i}_0)')\n",
    "            for q in q:\n",
    "                pred[j] = 1\n",
    "                break\n",
    "        pred = pred.astype(int)\n",
    "        preds.append(pred)\n",
    "\n",
    "    preds = np.stack(preds)\n",
    "    if labels is not None:\n",
    "        #metrics(labels, preds)\n",
    "        pass\n",
    "    return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing learned rules=====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   Call: (1) pyrun(\"consult('outputs/ag/rules_learned.pl')\", _6216) ? "
     ]
    }
   ],
   "source": [
    "masks = test_rules('outputs/ag/rules_learned.pl', 'prolog/ag/test_bk.pl', len(test_set), test_set.verb_classes)\n",
    "lightning_model.test_constraints = masks #list of verb masks, one for each example\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ilp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
